{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acYo4Na-Ih1X"
   },
   "source": [
    "# Capstone Discovery Problem Space: Language and cognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bId9nfjXIeu9"
   },
   "outputs": [],
   "source": [
    "!pip install pingouin\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import pingouin as pg\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "import pingouin\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "custom_style = {\n",
    "    \"axes.facecolor\": \"#343434\",\n",
    "    \"axes.edgecolor\": \"white\",\n",
    "    \"axes.labelcolor\": \"white\",\n",
    "    \"xtick.color\": \"white\",\n",
    "    \"ytick.color\": \"white\",\n",
    "    \"figure.facecolor\": \"#343434\",\n",
    "    \"grid.color\": \"none\",  # Remove gridlines\n",
    "    \"text.color\": \"white\",\n",
    "    \"lines.color\": \"white\",  # Default line color\n",
    "    \"lines.markeredgecolor\": \"white\",  # Default marker edge color\n",
    "    \"lines.markerfacecolor\": \"white\",  # Default marker face color\n",
    "}\n",
    "\n",
    "# Apply the custom style\n",
    "plt.rcParams.update(custom_style)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.vocab[\"\\n\"].is_stop = True\n",
    "nlp.max_length = 4353682\n",
    "\n",
    "def process(text):\n",
    "    parsed_text = nlp(text)\n",
    "    full_vocab = [token.lemma_.lower() for token in parsed_text \\\n",
    "                   if not token.is_stop and\\\n",
    "                   not token.is_punct\n",
    "                  #below I add some new criteria - CR\n",
    "                  and not token.text.strip() == ''       #remove empty text\n",
    "                  and token.is_ascii\n",
    "                  and re.match('[a-zA-Z]',token.text) #remove non ascii\n",
    "                  and not re.match('^[\\n]+$',token.text) #remove multiple line breaks\n",
    "                  and not token.like_url                 #remove urls\n",
    "                  and not '&nbsp' in token.text and not token.like_num]         # remove html garble\n",
    "    return full_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNTtaw_k_y3g"
   },
   "source": [
    "## Let's load some word norm data; these are numerical ratings of words along different cognitive and emotional dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K5znvP_C6N18"
   },
   "outputs": [],
   "source": [
    "norms = pd.read_pickle(\"https://raw.githubusercontent.com/texturejc/IGEL/main/public_norms.pkl\")\n",
    "\n",
    "# Note that this is unpublished data that I've compiled from various published sources. It's been rescaled\n",
    "# between 0 and 1 for all values, and some values are extraploated using machine learning. If you use it, please\n",
    "# note these caveats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "AB4-AG5SYhav",
    "outputId": "c618519e-f9cb-4977-f1ab-c1636e3ed363"
   },
   "outputs": [],
   "source": [
    "norms_sample = norms.sample(n= 20)\n",
    "\n",
    "sns.barplot(x = norms_sample.index, y = 'concreteness', color = 'white', data = norms_sample)\n",
    "plt.xticks(rotation=85)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "srUXist-ZdTv",
    "outputId": "e68e5699-799a-4063-8de6-2b8c6e1788b9"
   },
   "outputs": [],
   "source": [
    "sns.displot(norms['gustatory'], color = 'white', kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "GMJuGTvAu8NR",
    "outputId": "4ca983a8-c00f-4125-9b33-51447b3b3b9b"
   },
   "outputs": [],
   "source": [
    "categories = norms.columns\n",
    "\n",
    "word_1 = \"concept\"\n",
    "word_2 = \"cat\"\n",
    "\n",
    "word_1_values = norms.loc[word_1]\n",
    "word_2_values = norms.loc[word_2]\n",
    "\n",
    "# Create radar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=word_1_values,\n",
    "    theta=categories,\n",
    "    fill='toself',\n",
    "    name=word_1,\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=word_2_values,\n",
    "    theta=categories,\n",
    "    fill='toself',\n",
    "    name=word_2,\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Update layout for higher resolution and clearer text\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        bgcolor='#343434',\n",
    "        radialaxis=dict(visible=True, range=[0, 1], showticklabels=True, ticks=''),\n",
    "        angularaxis=dict(showticklabels=True, ticks='')\n",
    "    ),\n",
    "    paper_bgcolor='#343434',\n",
    "    plot_bgcolor='#343434',\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        font=dict(size=18, color='white')\n",
    "    ),\n",
    "    font=dict(size=16, color='white'),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "\n",
    "# Display the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBst07GOGH1N"
   },
   "source": [
    "## But what use is this data? Let's take Shakespeare's Sonnets as a starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x_xsS3nGTgs"
   },
   "source": [
    "### Load the sonnets from a text file and clean the text. The variable `clean` contains the individual sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NOj9olODZYRn"
   },
   "outputs": [],
   "source": [
    "sonnets = \"https://raw.githubusercontent.com/texturejc/IGEL/main/sonnets.txt\"\n",
    "\n",
    "texts = requests.get(sonnets)\n",
    "texts = texts.text\n",
    "\n",
    "sons = texts.split(\"\\r\\n\\r\\n\\r\\n\")\n",
    "\n",
    "clean = []\n",
    "\n",
    "for i in sons:\n",
    "    i = i.replace('\\ufeff', '')\n",
    "    i = i.replace('\\n', ' ')\n",
    "    i = i.replace('\\r', ' ')\n",
    "    i = i.strip()\n",
    "    clean.append(i)\n",
    "\n",
    "clean = [i.lower() for i in clean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3DTK_z_UX5T",
    "outputId": "2d47e214-e3af-4942-c9d9-f25bf4f5ccba"
   },
   "outputs": [],
   "source": [
    "print(sons[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnTl8zp6Gbv6"
   },
   "source": [
    "## Create two python functions that turns the texts into lemmas and scores them for our variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JuO9M0OYZBJf"
   },
   "outputs": [],
   "source": [
    "def word_norms(text):\n",
    "    lemmas = process(text)\n",
    "\n",
    "    words = []\n",
    "    norms_ = []\n",
    "\n",
    "    for i in lemmas:\n",
    "        if i in norms.index:\n",
    "            norms_.append(norms.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_df = pd.DataFrame(norms, index = words)\n",
    "    return norms_df\n",
    "\n",
    "def word_norms_mean(text):\n",
    "    lemmas = process(text)\n",
    "\n",
    "    words = []\n",
    "    norms_ = []\n",
    "\n",
    "    for i in lemmas:\n",
    "        if i in norms.index:\n",
    "            norms_.append(norms.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_df = pd.DataFrame(norms_)\n",
    "    return norms_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWP7VXwjGmAI",
    "outputId": "db989b75-60b2-415f-f82c-53b37376ed35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valence          0.606014\n",
       "arousal          0.391034\n",
       "dominance        0.592439\n",
       "auditory         0.329886\n",
       "gustatory        0.083915\n",
       "interoceptive    0.276977\n",
       "olfactory        0.107362\n",
       "visual           0.601539\n",
       "foot_leg         0.191936\n",
       "hand_arm         0.321097\n",
       "head             0.496878\n",
       "mouth            0.299357\n",
       "torso            0.218656\n",
       "concreteness     0.447777\n",
       "imageability     0.499000\n",
       "semantic_size    0.531463\n",
       "haptic           0.276342\n",
       "dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_norms_mean(clean[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7W7p9NsGnd2"
   },
   "source": [
    "### Let's get all our sonnets into a dataframe so we can work with them quantitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6oKm1BzCbBew"
   },
   "outputs": [],
   "source": [
    "over_time = []\n",
    "\n",
    "for i in clean:\n",
    "  over_time.append(word_norms_mean(i))\n",
    "\n",
    "over_time_df = pd.DataFrame(over_time)\n",
    "name = [\"Sonnet \"+str(i+1) for i in over_time_df.index]\n",
    "over_time_df['name'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "5bP4M_wDE773",
    "outputId": "e9ca2e14-4324-461c-81de-6a7d4e8336d9"
   },
   "outputs": [],
   "source": [
    "over_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "_L0_HOIWAg86",
    "outputId": "02095819-d0e9-4007-80f1-155104f6bb8b"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(over_time_df, x=over_time_df.index, y=\"valence\", hover_data = ['name'], trendline=\"ols\")\n",
    "fig.update_layout(\n",
    "    title= \"Trend over time in Shakespeare's Sonnets\",\n",
    "    paper_bgcolor=\"#343434\",\n",
    "    plot_bgcolor=\"#343434\",\n",
    "    font=dict(color='white'),\n",
    "    xaxis=dict(showgrid=True, title=\"Sonnet\"),\n",
    "    yaxis=dict(showgrid=True)\n",
    ")\n",
    "fig.update_traces(line=dict(color='red'), selector=dict(mode='lines'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "RmJt6EvZEapP",
    "outputId": "7c2f6542-40f7-46b8-843d-6f58de913793"
   },
   "outputs": [],
   "source": [
    "lm = pg.linear_regression(over_time_df.index, over_time_df['valence'])\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gn0Kjz0pSQnh"
   },
   "source": [
    "## So what else can we do with this data? Let's take a look at a corpus of Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "7LfH2DroSaHj",
    "outputId": "f676e476-82ee-4f73-a5d0-afd2d6b33836"
   },
   "outputs": [],
   "source": [
    "twitter = pd.read_pickle('https://raw.githubusercontent.com/texturejc/capstone_discovery_language/main/twitter_gender.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VnN6YgBv1MPL",
    "outputId": "cd763cb2-4719-4208-984b-ed5c366657f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'text', 'retweet_count', 'valence', 'arousal', 'dominance',\n",
       "       'auditory', 'gustatory', 'interoceptive', 'olfactory', 'visual',\n",
       "       'foot_leg', 'hand_arm', 'head', 'mouth', 'torso', 'concreteness',\n",
       "       'imageability', 'semantic_size', 'haptic', 'processed_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['cat', 'dog']\n",
    "\n",
    "filtered_df = twitter[twitter['processed_text'].apply(lambda text: any(word in text for word in word))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
